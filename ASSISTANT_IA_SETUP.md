# ü§ñ Guide d'Installation - Assistant IA Biblique

## üìã Vue d'ensemble

Ce guide vous accompagne dans l'installation et la configuration de l'assistant IA biblique pour SamaQuete, avec int√©gration des meilleurs mod√®les de langage (LLM) pour des r√©ponses pr√©cises bas√©es sur la Bible.

## üéØ LLM Recommand√©s

### 1. **Claude 3.5 Sonnet (Anthropic) - RECOMMAND√â**
- **Avantages** : Excellent pour les textes religieux, tr√®s pr√©cis
- **Co√ªt** : ~$3/million tokens entr√©e, ~$15/million tokens sortie
- **Qualit√©** : ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

### 2. **GPT-4o (OpenAI) - Alternative**
- **Avantages** : Large √©cosyst√®me, int√©gration facile
- **Co√ªt** : ~$2.50/million tokens entr√©e, ~$10/million tokens sortie
- **Qualit√©** : ‚≠ê‚≠ê‚≠ê‚≠ê

### 3. **Llama 3.1 70B (Meta) - Open Source**
- **Avantages** : Gratuit, contr√¥le total
- **Co√ªt** : Gratuit (co√ªts d'infrastructure)
- **Qualit√©** : ‚≠ê‚≠ê‚≠ê

## üöÄ Installation Rapide

### √âtape 1 : Installation des d√©pendances

```bash
# Installer les d√©pendances Python
pip install -r requirements_assistant.txt

# Ou avec conda
conda create -n assistant-ia python=3.9
conda activate assistant-ia
pip install -r requirements_assistant.txt
```

### √âtape 2 : Configuration des API Keys

```bash
# Copier le fichier d'exemple
cp env_example.txt .env

# √âditer le fichier .env avec vos cl√©s
nano .env
```

**Contenu du fichier .env :**
```env
# Anthropic Claude (Recommand√©)
ANTHROPIC_API_KEY=sk-ant-api03-...

# OpenAI GPT-4 (Alternative)
OPENAI_API_KEY=sk-...

# Configuration du serveur
FLASK_ENV=development
FLASK_DEBUG=True
PORT=8000
```

### √âtape 3 : Obtenir les API Keys

#### Pour Claude (Anthropic) :
1. Aller sur [console.anthropic.com](https://console.anthropic.com)
2. Cr√©er un compte
3. G√©n√©rer une cl√© API
4. **Co√ªt estim√©** : $5-20/mois pour 1000 utilisateurs

#### Pour OpenAI :
1. Aller sur [platform.openai.com](https://platform.openai.com)
2. Cr√©er un compte
3. Ajouter des cr√©dits ($5 minimum)
4. G√©n√©rer une cl√© API
5. **Co√ªt estim√©** : $3-15/mois pour 1000 utilisateurs

### √âtape 4 : D√©marrer le serveur

```bash
# D√©marrer l'assistant IA
python assistant_biblique_enhanced.py
```

Vous devriez voir :
```
üöÄ D√©marrage de l'Assistant Biblique IA
üìö Mod√®les disponibles:
   - Claude 3.5 Sonnet: ‚úÖ
   - GPT-4o: ‚úÖ
üåê Serveur d√©marr√© sur http://localhost:8000
```

## üì± Int√©gration Mobile

### √âtape 1 : Mettre √† jour l'√©cran Assistant

```typescript
// Dans votre App.tsx ou composant principal
import AssistantScreenEnhanced from './src/components/screens/assistant/AssistantScreenEnhanced';

// Remplacer l'ancien AssistantScreen par AssistantScreenEnhanced
```

### √âtape 2 : Configuration de l'URL API

```typescript
// Dans lib/assistantService.ts
const API_BASE_URL = 'http://votre-serveur.com:8000'; // URL de production
```

## üí∞ Strat√©gies d'Optimisation des Co√ªts

### 1. **Cache Intelligent**
- Les r√©ponses sont mises en cache pendant 1 heure
- R√©duction des co√ªts de 60-80%

### 2. **Limitation des Tokens**
- R√©ponses limit√©es √† 1000 tokens
- Pr√©vention des r√©ponses trop longues

### 3. **Fallback Strategy**
- Claude en priorit√© (meilleure qualit√©)
- GPT-4 en fallback (co√ªt r√©duit)
- R√©ponse basique si erreur

### 4. **Filtrage des Questions**
```python
# Questions trop courtes ou inappropri√©es
if len(question) < 5 or question.lower() in ['salut', 'bonjour']:
    return "Veuillez poser une question plus sp√©cifique sur la foi."
```

## üîß Configuration Avanc√©e

### Variables d'Environnement

```env
# Configuration des mod√®les
PREFERRED_MODEL=claude  # claude, gpt4, ou auto
MAX_TOKENS=1000
CACHE_DURATION=3600  # secondes

# Configuration de s√©curit√©
RATE_LIMIT=100  # requ√™tes par heure par IP
MAX_QUESTION_LENGTH=500

# Configuration de monitoring
ENABLE_LOGGING=true
LOG_LEVEL=INFO
```

### Monitoring et Logs

```python
# Les logs incluent :
# - Questions pos√©es
# - R√©ponses g√©n√©r√©es
# - Temps de r√©ponse
# - Co√ªts par requ√™te
# - Erreurs
```

## üöÄ D√©ploiement en Production

### Option 1 : Serveur D√©di√©

```bash
# Installation sur Ubuntu/Debian
sudo apt update
sudo apt install python3-pip nginx

# Installation des d√©pendances
pip3 install -r requirements_assistant.txt

# Configuration Nginx
sudo nano /etc/nginx/sites-available/assistant-ia
```

**Configuration Nginx :**
```nginx
server {
    listen 80;
    server_name votre-domaine.com;

    location / {
        proxy_pass http://127.0.0.1:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

### Option 2 : Docker

```dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements_assistant.txt .
RUN pip install -r requirements_assistant.txt

COPY . .
EXPOSE 8000

CMD ["python", "assistant_biblique_enhanced.py"]
```

```bash
# Build et run
docker build -t assistant-ia .
docker run -p 8000:8000 --env-file .env assistant-ia
```

### Option 3 : Cloud (AWS/GCP/Azure)

**AWS Lambda + API Gateway :**
- Co√ªt : ~$10-30/mois
- Scalabilit√© automatique
- Pas de gestion de serveur

**Google Cloud Run :**
- Co√ªt : ~$15-40/mois
- D√©ploiement facile
- Monitoring int√©gr√©

## üìä Monitoring et Analytics

### M√©triques Importantes

1. **Performance**
   - Temps de r√©ponse moyen
   - Taux de succ√®s des requ√™tes
   - Utilisation du cache

2. **Co√ªts**
   - Tokens utilis√©s par jour
   - Co√ªt par requ√™te
   - Pr√©vision des co√ªts mensuels

3. **Qualit√©**
   - Score de confiance moyen
   - Questions les plus fr√©quentes
   - Taux de satisfaction utilisateur

### Dashboard de Monitoring

```python
# Endpoint de statistiques
GET /api/assistant/stats

# R√©ponse
{
  "cached_responses": 150,
  "models_available": {
    "claude": true,
    "gpt4": true
  },
  "daily_requests": 45,
  "average_response_time": 2.3,
  "total_cost_today": 0.85
}
```

## üîí S√©curit√©

### Mesures Impl√©ment√©es

1. **Rate Limiting** : 100 requ√™tes/heure par IP
2. **Validation des entr√©es** : Filtrage des questions inappropri√©es
3. **Logs de s√©curit√©** : Tra√ßabilit√© des requ√™tes
4. **HTTPS** : Chiffrement des communications

### Recommandations

```python
# Ajouter √† votre configuration
SECRET_KEY = "votre-cl√©-secr√®te"
ALLOWED_ORIGINS = ["https://votre-app.com"]
MAX_QUESTION_LENGTH = 500
```

## üÜò D√©pannage

### Probl√®mes Courants

**1. Erreur de connexion API**
```bash
# V√©rifier les cl√©s API
echo $ANTHROPIC_API_KEY
echo $OPENAI_API_KEY

# Tester la connexion
curl -X POST http://localhost:8000/api/assistant/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Test"}'
```

**2. Co√ªts trop √©lev√©s**
- Activer le cache
- R√©duire MAX_TOKENS
- Impl√©menter le rate limiting

**3. R√©ponses de mauvaise qualit√©**
- V√©rifier le contexte biblique
- Ajuster la temp√©rature du mod√®le
- Am√©liorer les prompts

### Support

- **Logs** : V√©rifier les logs du serveur
- **Tests** : Utiliser l'endpoint `/health`
- **Monitoring** : Surveiller les m√©triques

## üìà √âvolutions Futures

### Am√©liorations Pr√©vues

1. **Base de donn√©es biblique locale**
   - R√©duction des co√ªts
   - R√©ponses plus rapides
   - Contr√¥le total

2. **Fine-tuning du mod√®le**
   - Entra√Ænement sur des textes catholiques
   - Meilleure compr√©hension du contexte

3. **Interface d'administration**
   - Gestion des questions fr√©quentes
   - Monitoring en temps r√©el
   - Configuration des mod√®les

4. **Int√©gration multilingue**
   - Support Wolof, Fran√ßais, Anglais
   - R√©ponses contextuelles par langue

---

## üéâ F√©licitations !

Votre assistant IA biblique est maintenant pr√™t ! Vous avez :

‚úÖ Un serveur Python avec int√©gration LLM  
‚úÖ Une application mobile connect√©e  
‚úÖ Des strat√©gies d'optimisation des co√ªts  
‚úÖ Un syst√®me de monitoring  
‚úÖ Des mesures de s√©curit√©  

**Prochaines √©tapes :**
1. Tester avec quelques questions
2. Configurer le monitoring
3. D√©ployer en production
4. Former vos utilisateurs

**Besoin d'aide ?** Consultez les logs ou contactez l'√©quipe de d√©veloppement.
